<div class="step-text">
<h5 id="description">Description</h5>
<p></p><div class="alert alert-primary"> Before we start, let's discuss a few things. First of all, we use the <code class="java">titanic</code> dataset in this project. We have already prepared data for you, so enjoy simply  creating the algorithm!

<p>We also need you to provide the desired outputs as Python lists so that our tests would work correctly when there is more than one value to be printed. You can always make <code class="java">list(..)</code> of your <code class="java">np.ndarray</code> to convert it to a list.</p>
<p>Finally, this project includes dealing with randomness. To counter it, use seed <code class="java"><span style="color: #000000;">52</span></code> wherever possible.</p></div>
<p>Firstly, test how well a simple standalone decision tree works to have something to compare with. It will also come in handy, as we will need to use those in the Forest too.</p>
<p>Our data quality is fine, so we will stick to the simplest metric â€” accuracy. Fit the model to the train set and then make a prediction for the test set. Next, calculate the accuracy. You could use accuracy from <code class="java">sklearn</code> to avoid any complexities.</p>
<h5 id="objectives">Objectives</h5>
<ol>
<li>Use the <code class="java">sklearn</code>'s <code class="java">DecisionTreeClassifier</code> to create a decision tree.</li>
<li>Fit the model to the train set and make a prediction for the test set.</li>
<li>Print accuracy of the predictions using <code class="java">sklearn</code>'s <code class="java">accuracy_score</code> rounded to three digits after the dot (for example, 3.141).</li>
</ol>
<h5 id="example">Example</h5>
<p><strong>Example 1</strong>: <em>example of the output</em></p>
<pre><code class="language-no-highlight">0.789</code></pre>

</div>